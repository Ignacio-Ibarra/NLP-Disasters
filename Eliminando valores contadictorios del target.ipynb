{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP1 version Ale.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ignacio-Ibarra/NLP-Disasters/blob/tp1_nlp_disasters---edits/Eliminando%20valores%20contadictorios%20del%20target.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em1a8pjEul4W",
        "colab_type": "text"
      },
      "source": [
        "## Eliminando valores contradictorios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJlc0AI_QZYr",
        "colab_type": "text"
      },
      "source": [
        "Librerias\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD5hp2AiNQDz",
        "colab_type": "code",
        "outputId": "4eb72ed1-392c-4665-a86c-011a4df5b594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('ggplot')\n",
        "from wordcloud import WordCloud\n",
        "import PIL\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop=set(stopwords.words('english'))\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "#para suprimir notacion cientifica en los outputs\n",
        "pd.options.display.float_format='{:20,.2f}'.format\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAUmA9iHTe--",
        "colab_type": "text"
      },
      "source": [
        "Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI1kyzzgSAbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ui6ouJ_SVwz",
        "colab_type": "code",
        "outputId": "e8ba1d85-d9bd-4970-9d94-830a6a6b4668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "link='https://drive.google.com/open?id=1Wuo42Fju9VOh2m5PV7q95TTUAIkrEwDD'\n",
        "fluff, id = link.split('=')\n",
        "print (id) # Verify that you have everything after '='"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1Wuo42Fju9VOh2m5PV7q95TTUAIkrEwDD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FljNTbTSigo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkZHvF9eSUqL",
        "colab_type": "text"
      },
      "source": [
        "Carga DF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHLtylTOSxYC",
        "colab_type": "code",
        "outputId": "e97529db-f61c-461c-ad38-b6ec4762d35e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "#Loading 'train.csv' into DataFrame\n",
        "train=pd.read_csv('train.csv')\n",
        "train.head(10) #Let's have a first view of the DataFrame"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>There's an emergency evacuation happening now ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "5   8     NaN  ...  #RockyFire Update => California Hwy. 20 closed...      1\n",
              "6  10     NaN  ...  #flood #disaster Heavy rain causes flash flood...      1\n",
              "7  13     NaN  ...  I'm on top of the hill and I can see a fire in...      1\n",
              "8  14     NaN  ...  There's an emergency evacuation happening now ...      1\n",
              "9  15     NaN  ...  I'm afraid that the tornado is coming to our a...      1\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM8fF1mfLlQG",
        "colab_type": "code",
        "outputId": "057e129b-e6d2-4129-c70d-39172b4328be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('El DataFrame cuenta con {} filas y {} columnas'.format(train.shape[0],train.shape[1]))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El DataFrame cuenta con 7613 filas y 5 columnas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED_1fcrro2Ll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "3c3563f9-1c50-43ab-dfdf-40bba0541ae7"
      },
      "source": [
        "train.groupby('text').agg({'target':['count','nunique']}).sort_values(by=('target','nunique'),ascending=False).head(15)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>nunique</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Enugu Government to demolish illegal structures at International Conference Centre</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.POTUS  is a strategy for  refugees; IDP Internally displaced people; horror; etc.</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Why are you deluged with low self-image? Take the quiz:</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pandemonium In Aba As Woman Delivers Baby Without Face (Photos) -</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mmmmmm I'm burning.... I'm burning buildings I'm building.... Oooooohhhh oooh ooh...</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RT NotExplained: The only known image of infamous hijacker D.B. Cooper.</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps  via</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>that horrible sinking feeling when youÛªve been at home on your phone for a while and you realise its been on 3G this whole time</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>slips into loss after   unsafe and hazardous for</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TY for the follow Go To  BRUTALLY ABUSED+DESOLATE&amp;amp;LOST + HER LOVELY MUM DIES..Is it Murder?</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Prophet (peace be upon him) said 'Save yourself from Hellfire even if it is by giving half a date in charity.'</th>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>To fight bioterrorism sir.</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Angry Woman Openly Accuses NEMA Of Stealing Relief Materials Meant For IDPs: An angry Internally Displaced wom...</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>describes piling up  thinking it would last  as the description of the people of  in Surah Humaza.</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sassy city girl country hunk stranded in Smoky Mountain snowstorm</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   target        \n",
              "                                                    count nunique\n",
              "text                                                             \n",
              "Enugu Government to demolish illegal structures...      3       2\n",
              ".POTUS  is a strategy for  refugees; IDP Intern...      5       2\n",
              "Why are you deluged with low self-image? Take t...      2       2\n",
              "Pandemonium In Aba As Woman Delivers Baby Witho...      5       2\n",
              "Mmmmmm I'm burning.... I'm burning buildings I'...      2       2\n",
              "RT NotExplained: The only known image of infamo...      2       2\n",
              "FedEx no longer to transport bioterror germs in...      4       2\n",
              "that horrible sinking feeling when youÛªve bee...      4       2\n",
              "   slips into loss after   unsafe and hazardous...      3       2\n",
              " TY for the follow Go To  BRUTALLY ABUSED+DESOL...      2       2\n",
              "The Prophet (peace be upon him) said 'Save your...      6       2\n",
              "To fight bioterrorism sir.                              4       2\n",
              "Angry Woman Openly Accuses NEMA Of Stealing Rel...      3       2\n",
              " describes piling up  thinking it would last  a...      3       2\n",
              "Sassy city girl country hunk stranded in Smoky ...      3       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBDlApEcujeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRzhmdxUZSCp",
        "colab_type": "text"
      },
      "source": [
        "Nos parece importante no tener 'target' que sean contradictorios si tenemos textos iguales. Para eso sacamos los url, mentions y hashtags de los textos para poder considerarlos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7bQC8_4TYwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creo un DataFrame nuevo para no pisar 'train', en el nuevo voy a sacar los url, mentions y hashtags de los textos\n",
        "train_no_url_mentions_hashtags = train\n",
        "\n",
        "#Saco los url, mentions y hashtags de los textos\n",
        "train_no_url_mentions_hashtags['text']=train['text'].str.replace('http\\S+|HTTP\\S+|www.\\S+|WWW.\\S+|@\\S+|#\\S+', '', case=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhJNh8NTWBDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Agrupo por texto, calculo el 'nunique' de los targets y hago el transform para agregar columna al dataframe\n",
        "train_no_url_mentions_hashtags['target_nunique']=train_no_url_mentions_hashtags.groupby('text')['target'].transform('nunique')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHe8AyP9ot2g",
        "colab_type": "code",
        "outputId": "2c478236-b277-4e1d-8bcc-3f9f4392403e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Me quedo sólo con los que tienen 'target_nunique'==1\n",
        "train_no_url_mentions_hashtags=train_no_url_mentions_hashtags[train_no_url_mentions_hashtags.loc[:,'target_nunique']==1]\n",
        "\n",
        "#Borro la columna 'target_nunique'. \n",
        "train_no_url_mentions_hashtags.drop(columns='target_nunique',inplace=True)\n",
        "\n",
        "#Shape del df\n",
        "train_no_url_mentions_hashtags.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7368, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyPPcxGGu_wa",
        "colab_type": "text"
      },
      "source": [
        "El dataset queda con 7368 filas. "
      ]
    }
  ]
}