{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ignacio-Ibarra/NLP-Disasters/blob/master/VERSION%20FINAL/TP%202/Modelos/LSTM/Preprocesing/Preprocessing2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALI-jb3BCH8b",
        "colab_type": "text"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt-gp1qks6f7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "0f056316-2add-406f-e6b3-bc25a861e9f6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import spacy\n",
        "import string\n",
        "pd.options.mode.chained_assignment = None\n",
        "!pip install emot\n",
        "import emot\n",
        "from emot.core import emoji\n",
        "from emot.core import emoticons\n",
        "from emot.emo_unicode import EMO_UNICODE\n",
        "from emot.emo_unicode import UNICODE_EMO\n",
        "from emot.emo_unicode import EMOTICONS\n",
        "!pip install pyspellchecker\n",
        "from spellchecker import SpellChecker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Collecting emot\n",
            "  Downloading https://files.pythonhosted.org/packages/49/07/20001ade19873de611b7b66a4d5e5aabbf190d65abea337d5deeaa2bc3de/emot-2.1-py3-none-any.whl\n",
            "Installing collected packages: emot\n",
            "Successfully installed emot-2.1\n",
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/ec4e830e9f9c1fd788e1459dd09279fdf807bc7a475579fd7192450b879c/pyspellchecker-0.5.4-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU61Dp19CGn2",
        "colab_type": "text"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHj2y3ekCOXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(r'https://raw.githubusercontent.com/Ignacio-Ibarra/NLP-Disasters/intento_3_nachos/Datasets%20Kaggle/train.csv')\n",
        "test = pd.read_csv(r'https://raw.githubusercontent.com/Ignacio-Ibarra/NLP-Disasters/intento_3_nachos/Datasets%20Kaggle/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yj0ppfxDbwM",
        "colab_type": "text"
      },
      "source": [
        "# Filling nulls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y831rrU-Dj-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filling nulls columns 'location' and 'keyword'\n",
        "\n",
        "train['keyword'].fillna('no_keyword',inplace=True)\n",
        "test['keyword'].fillna('no_keyword', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HsJemPVEaK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a column in the test set to equal the number of columns in train set \n",
        "test['target'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjtnfR3CDmBr",
        "colab_type": "text"
      },
      "source": [
        "# Appending both datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUjz7k_w1mjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['istrain'] = 1\n",
        "test['istrain'] = 0\n",
        "complete = train.append(test).reset_index().drop(columns = 'index')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCtRpZrM14k5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "complete['text'] = complete[\"text\"].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvS_Yuqhd7-k",
        "colab_type": "text"
      },
      "source": [
        "# CHAT WORDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHq_TXnT7yjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing chat words\n",
        "\n",
        "#This is a pandas df with many types of \"chat words\"\n",
        "slang = pd.read_csv(r'https://raw.githubusercontent.com/Ignacio-Ibarra/NLP-Disasters/intento_3_nachos/intento_3/slang.txt', sep = '=', names = ['slang','meaning'])\n",
        "\n",
        "def replace_chat_word(text): \n",
        "  line = []\n",
        "  for i in text.split(): \n",
        "    if i in slang.slang.to_list(): \n",
        "      i = slang.loc[slang.slang == i,'meaning'].values[0].lower()\n",
        "      line.append(i)\n",
        "    else: \n",
        "      line.append(i)\n",
        "  return str(\" \".join(line))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAWFAMwjhFBV",
        "colab_type": "text"
      },
      "source": [
        "# URL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bp3Rmv8hEq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_url(text):\n",
        "  text = re.sub(r'http\\S+', '', text)  \n",
        "  text = re.sub(r'https\\S+', '', text)\n",
        "  text = re.sub(r'www\\S+','',text)\n",
        "    \n",
        "  return (text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKcse8j6d0LS",
        "colab_type": "text"
      },
      "source": [
        "# EMOJIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLGcGubK3o5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fb823IQd_NF",
        "colab_type": "text"
      },
      "source": [
        "# EMOTICONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVW_YUkwW2Lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_emoticons(text):\n",
        "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n",
        "    return emoticon_pattern.sub(r'', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHxDPFiQd4A6",
        "colab_type": "text"
      },
      "source": [
        "# HTML TAGS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NopIRlRP7i6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_html(text):\n",
        "    html_pattern = re.compile('<.*?>')\n",
        "    return html_pattern.sub(r'', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaOXf6v98XSB",
        "colab_type": "text"
      },
      "source": [
        "# SPECIAL CHARACTERS, PUNCTUACION, TYPOS, OTHER SLANGS, ABBREVIATIONS "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HOB4dlRVrhY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Credit: Gunes Evitan\n",
        "#https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-full-cleaning#4.-Embeddings-&-tweet-Cleaning\n",
        "\n",
        "def gunes_evitan(tweet):\n",
        "    \n",
        "    # Punctuations at the start or end of words    \n",
        "    for punctuation in \"#@!?()[]*%\":\n",
        "      tweet = tweet.replace(punctuation, f' {punctuation} ').strip()\n",
        "        \n",
        "    tweet = tweet.replace('...', ' ... ').strip()\n",
        "    tweet = tweet.replace(\"'\", \" ' \").strip()   \n",
        "\n",
        "\n",
        "    # Special characters\n",
        "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
        "    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
        "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
        "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n",
        "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
        "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
        "    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
        "    \n",
        "    # Contractions\n",
        "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
        "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
        "    tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
        "    tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
        "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
        "    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
        "    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
        "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
        "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
        "    tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
        "    tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
        "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
        "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
        "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
        "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
        "    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
        "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
        "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
        "    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
        "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
        "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
        "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
        "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
        "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
        "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
        "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
        "    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
        "    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
        "    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
        "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
        "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
        "    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
        "    \n",
        "    # Character entity references\n",
        "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
        "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
        "    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n",
        "        \n",
        "    # Typos, slang and informal abbreviations\n",
        "    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n",
        "    tweet = re.sub(r\"w/\", \"with\", tweet)\n",
        "    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n",
        "    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n",
        "    tweet = re.sub(r\"Ph0tos\", \"Photos\", tweet)\n",
        "    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n",
        "    tweet = re.sub(r\"<3\", \"love\", tweet)\n",
        "    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n",
        "    tweet = re.sub(r\"Trfc\", \"Traffic\", tweet)\n",
        "    tweet = re.sub(r\"8/5/2015\", \"2015-08-05\", tweet)\n",
        "    tweet = re.sub(r\"chest/torso\", \"chest / torso\", tweet)\n",
        "    tweet = re.sub(r\"WindStorm\", \"Wind Storm\", tweet)\n",
        "    tweet = re.sub(r\"8/6/2015\", \"2015-08-06\", tweet)\n",
        "    tweet = re.sub(r\"10:38PM\", \"10:38 PM\", tweet)\n",
        "    tweet = re.sub(r\"10:30pm\", \"10:30 PM\", tweet)\n",
        "    \n",
        "    # Separating other punctuations\n",
        "    tweet = re.sub(r\"MH370:\", \"MH370 :\", tweet)\n",
        "    tweet = re.sub(r\"PM:\", \"Prime Minister :\", tweet)\n",
        "    tweet = re.sub(r\"Legionnaires:\", \"Legionnaires :\", tweet)\n",
        "    tweet = re.sub(r\"Latest:\", \"Latest :\", tweet)\n",
        "    tweet = re.sub(r\"Crash:\", \"Crash :\", tweet)\n",
        "    tweet = re.sub(r\"News:\", \"News :\", tweet)\n",
        "    tweet = re.sub(r\"derailment:\", \"derailment :\", tweet)\n",
        "    tweet = re.sub(r\"attack:\", \"attack :\", tweet)\n",
        "    tweet = re.sub(r\"Saipan:\", \"Saipan :\", tweet)\n",
        "    tweet = re.sub(r\"Photo:\", \"Photo :\", tweet)\n",
        "    tweet = re.sub(r\"Funtenna:\", \"Funtenna :\", tweet)\n",
        "    tweet = re.sub(r\"quiz:\", \"quiz :\", tweet)\n",
        "    tweet = re.sub(r\"VIDEO:\", \"VIDEO :\", tweet)\n",
        "    tweet = re.sub(r\"MP:\", \"MP :\", tweet)\n",
        "    tweet = re.sub(r\"UTC2015-08-05\", \"UTC 2015-08-05\", tweet)\n",
        "    tweet = re.sub(r\"California:\", \"California :\", tweet)\n",
        "    tweet = re.sub(r\"horror:\", \"horror :\", tweet)\n",
        "    tweet = re.sub(r\"Past:\", \"Past :\", tweet)\n",
        "    tweet = re.sub(r\"Time2015-08-06\", \"Time 2015-08-06\", tweet)\n",
        "    tweet = re.sub(r\"here:\", \"here :\", tweet)\n",
        "    tweet = re.sub(r\"fires.\", \"fires .\", tweet)\n",
        "    tweet = re.sub(r\"Forest:\", \"Forest :\", tweet)\n",
        "    tweet = re.sub(r\"Cramer:\", \"Cramer :\", tweet)\n",
        "    tweet = re.sub(r\"Chile:\", \"Chile :\", tweet)\n",
        "    tweet = re.sub(r\"link:\", \"link :\", tweet)\n",
        "    tweet = re.sub(r\"crash:\", \"crash :\", tweet)\n",
        "    tweet = re.sub(r\"Video:\", \"Video :\", tweet)\n",
        "    tweet = re.sub(r\"Bestnaijamade:\", \"bestnaijamade :\", tweet)\n",
        "    tweet = re.sub(r\"NWS:\", \"National Weather Service :\", tweet)\n",
        "    tweet = re.sub(r\".caught\", \". caught\", tweet)\n",
        "    tweet = re.sub(r\"Hobbit:\", \"Hobbit :\", tweet)\n",
        "    tweet = re.sub(r\"2015:\", \"2015 :\", tweet)\n",
        "    tweet = re.sub(r\"post:\", \"post :\", tweet)\n",
        "    tweet = re.sub(r\"BREAKING:\", \"BREAKING :\", tweet)\n",
        "    tweet = re.sub(r\"Island:\", \"Island :\", tweet)\n",
        "    tweet = re.sub(r\"Med:\", \"Med :\", tweet)\n",
        "    tweet = re.sub(r\"97/Georgia\", \"97 / Georgia\", tweet)\n",
        "    tweet = re.sub(r\"Here:\", \"Here :\", tweet)\n",
        "    tweet = re.sub(r\"horror;\", \"horror ;\", tweet)\n",
        "    tweet = re.sub(r\"people;\", \"people ;\", tweet)\n",
        "    tweet = re.sub(r\"refugees;\", \"refugees ;\", tweet)\n",
        "    tweet = re.sub(r\"Genocide;\", \"Genocide ;\", tweet)\n",
        "    tweet = re.sub(r\".POTUS\", \". POTUS\", tweet)\n",
        "    tweet = re.sub(r\"Collision-No\", \"Collision - No\", tweet)\n",
        "    tweet = re.sub(r\"Rear-\", \"Rear -\", tweet)\n",
        "    tweet = re.sub(r\"Broadway:\", \"Broadway :\", tweet)\n",
        "    tweet = re.sub(r\"Correction:\", \"Correction :\", tweet)\n",
        "    tweet = re.sub(r\"UPDATE:\", \"UPDATE :\", tweet)\n",
        "    tweet = re.sub(r\"Times:\", \"Times :\", tweet)\n",
        "    tweet = re.sub(r\"RT:\", \"RT :\", tweet)\n",
        "    tweet = re.sub(r\"Police:\", \"Police :\", tweet)\n",
        "    tweet = re.sub(r\"Training:\", \"Training :\", tweet)\n",
        "    tweet = re.sub(r\"Hawaii:\", \"Hawaii :\", tweet)\n",
        "    tweet = re.sub(r\"Selfies:\", \"Selfies :\", tweet)\n",
        "    tweet = re.sub(r\"Content:\", \"Content :\", tweet)\n",
        "    tweet = re.sub(r\"101:\", \"101 :\", tweet)\n",
        "    tweet = re.sub(r\"story:\", \"story :\", tweet)\n",
        "    tweet = re.sub(r\"injured:\", \"injured :\", tweet)\n",
        "    tweet = re.sub(r\"poll:\", \"poll :\", tweet)\n",
        "    tweet = re.sub(r\"Guide:\", \"Guide :\", tweet)\n",
        "    tweet = re.sub(r\"Update:\", \"Update :\", tweet)\n",
        "    tweet = re.sub(r\"alarm:\", \"alarm :\", tweet)\n",
        "    tweet = re.sub(r\"floods:\", \"floods :\", tweet)\n",
        "    tweet = re.sub(r\"Flood:\", \"Flood :\", tweet)\n",
        "    tweet = re.sub(r\"MH370;\", \"MH370 ;\", tweet)\n",
        "    tweet = re.sub(r\"life:\", \"life :\", tweet)\n",
        "    tweet = re.sub(r\"crush:\", \"crush :\", tweet)\n",
        "    tweet = re.sub(r\"now:\", \"now :\", tweet)\n",
        "    tweet = re.sub(r\"Vote:\", \"Vote :\", tweet)\n",
        "    tweet = re.sub(r\"Catastrophe.\", \"Catastrophe .\", tweet)\n",
        "    tweet = re.sub(r\"library:\", \"library :\", tweet)\n",
        "    tweet = re.sub(r\"Bush:\", \"Bush :\", tweet)\n",
        "    tweet = re.sub(r\";ACCIDENT\", \"; ACCIDENT\", tweet)\n",
        "    tweet = re.sub(r\"accident:\", \"accident :\", tweet)\n",
        "    tweet = re.sub(r\"Taiwan;\", \"Taiwan ;\", tweet)\n",
        "    tweet = re.sub(r\"Map:\", \"Map :\", tweet)\n",
        "    tweet = re.sub(r\"failure:\", \"failure :\", tweet)\n",
        "    tweet = re.sub(r\"150-Foot\", \"150 - Foot\", tweet)\n",
        "    tweet = re.sub(r\"failure:\", \"failure :\", tweet)\n",
        "    tweet = re.sub(r\"prefer:\", \"prefer :\", tweet)\n",
        "    tweet = re.sub(r\"CNN:\", \"CNN :\", tweet)\n",
        "    tweet = re.sub(r\"Oops:\", \"Oops :\", tweet)\n",
        "    tweet = re.sub(r\"Disco:\", \"Disco :\", tweet)\n",
        "    tweet = re.sub(r\"Disease:\", \"Disease :\", tweet)\n",
        "    tweet = re.sub(r\"Grows:\", \"Grows :\", tweet)\n",
        "    tweet = re.sub(r\"projected:\", \"projected :\", tweet)\n",
        "    tweet = re.sub(r\"Pakistan.\", \"Pakistan .\", tweet)\n",
        "    tweet = re.sub(r\"ministers:\", \"ministers :\", tweet)\n",
        "    tweet = re.sub(r\"Photos:\", \"Photos :\", tweet)\n",
        "    tweet = re.sub(r\"Disease:\", \"Disease :\", tweet)\n",
        "    tweet = re.sub(r\"pres:\", \"press :\", tweet)\n",
        "    tweet = re.sub(r\"winds.\", \"winds .\", tweet)\n",
        "    tweet = re.sub(r\"MPH.\", \"MPH .\", tweet)\n",
        "    tweet = re.sub(r\"PHOTOS:\", \"PHOTOS :\", tweet)\n",
        "    tweet = re.sub(r\"Time2015-08-05\", \"Time 2015-08-05\", tweet)\n",
        "    tweet = re.sub(r\"Denmark:\", \"Denmark :\", tweet)\n",
        "    tweet = re.sub(r\"Articles:\", \"Articles :\", tweet)\n",
        "    tweet = re.sub(r\"Crash:\", \"Crash :\", tweet)\n",
        "    tweet = re.sub(r\"casualties.:\", \"casualties .:\", tweet)\n",
        "    tweet = re.sub(r\"Afghanistan:\", \"Afghanistan :\", tweet)\n",
        "    tweet = re.sub(r\"Day:\", \"Day :\", tweet)\n",
        "    tweet = re.sub(r\"AVERTED:\", \"AVERTED :\", tweet)\n",
        "    tweet = re.sub(r\"sitting:\", \"sitting :\", tweet)\n",
        "    tweet = re.sub(r\"Multiplayer:\", \"Multiplayer :\", tweet)\n",
        "    tweet = re.sub(r\"Kaduna:\", \"Kaduna :\", tweet)\n",
        "    tweet = re.sub(r\"favorite:\", \"favorite :\", tweet)\n",
        "    tweet = re.sub(r\"home:\", \"home :\", tweet)\n",
        "    tweet = re.sub(r\"just:\", \"just :\", tweet)\n",
        "    tweet = re.sub(r\"Collision-1141\", \"Collision - 1141\", tweet)\n",
        "    tweet = re.sub(r\"County:\", \"County :\", tweet)\n",
        "    tweet = re.sub(r\"Duty:\", \"Duty :\", tweet)\n",
        "    tweet = re.sub(r\"page:\", \"page :\", tweet)\n",
        "    tweet = re.sub(r\"Attack:\", \"Attack :\", tweet)\n",
        "    tweet = re.sub(r\"Minecraft:\", \"Minecraft :\", tweet)\n",
        "    tweet = re.sub(r\"wounds;\", \"wounds ;\", tweet)\n",
        "    tweet = re.sub(r\"Shots:\", \"Shots :\", tweet)\n",
        "    tweet = re.sub(r\"shots:\", \"shots :\", tweet)\n",
        "    tweet = re.sub(r\"Gunfire:\", \"Gunfire :\", tweet)\n",
        "    tweet = re.sub(r\"hike:\", \"hike :\", tweet)\n",
        "    tweet = re.sub(r\"Email:\", \"Email :\", tweet)\n",
        "    tweet = re.sub(r\"System:\", \"System :\", tweet)\n",
        "    tweet = re.sub(r\"Radio:\", \"Radio :\", tweet)\n",
        "    tweet = re.sub(r\"King:\", \"King :\", tweet)\n",
        "    tweet = re.sub(r\"upheaval:\", \"upheaval :\", tweet)\n",
        "    tweet = re.sub(r\"tragedy;\", \"tragedy ;\", tweet)\n",
        "    tweet = re.sub(r\"HERE:\", \"HERE :\", tweet)\n",
        "    tweet = re.sub(r\"terrorism:\", \"terrorism :\", tweet)\n",
        "    tweet = re.sub(r\"police:\", \"police :\", tweet)\n",
        "    tweet = re.sub(r\"Mosque:\", \"Mosque :\", tweet)\n",
        "    tweet = re.sub(r\"Rightways:\", \"Rightways :\", tweet)\n",
        "    tweet = re.sub(r\"Brooklyn:\", \"Brooklyn :\", tweet)\n",
        "    tweet = re.sub(r\"Arrived:\", \"Arrived :\", tweet)\n",
        "    tweet = re.sub(r\"Home:\", \"Home :\", tweet)\n",
        "    tweet = re.sub(r\"Earth:\", \"Earth :\", tweet)\n",
        "    tweet = re.sub(r\"three:\", \"three :\", tweet)\n",
        "    \n",
        "    \n",
        "    # Hashtags and usernames\n",
        "    tweet = re.sub(r\"IranDeal\", \"Iran Deal\", tweet)\n",
        "    tweet = re.sub(r\"ArianaGrande\", \"Ariana Grande\", tweet)\n",
        "    tweet = re.sub(r\"camilacabello97\", \"camila cabello\", tweet) \n",
        "    tweet = re.sub(r\"RondaRousey\", \"Ronda Rousey\", tweet)     \n",
        "    tweet = re.sub(r\"MTVHottest\", \"MTV Hottest\", tweet)\n",
        "    tweet = re.sub(r\"TrapMusic\", \"Trap Music\", tweet)\n",
        "    tweet = re.sub(r\"ProphetMuhammad\", \"Prophet Muhammad\", tweet)\n",
        "    tweet = re.sub(r\"PantherAttack\", \"Panther Attack\", tweet)\n",
        "    tweet = re.sub(r\"StrategicPatience\", \"Strategic Patience\", tweet)\n",
        "    tweet = re.sub(r\"socialnews\", \"social news\", tweet)\n",
        "    tweet = re.sub(r\"NASAHurricane\", \"NASA Hurricane\", tweet)\n",
        "    tweet = re.sub(r\"onlinecommunities\", \"online communities\", tweet)\n",
        "    tweet = re.sub(r\"humanconsumption\", \"human consumption\", tweet)\n",
        "    tweet = re.sub(r\"Typhoon-Devastated\", \"Typhoon Devastated\", tweet)\n",
        "    tweet = re.sub(r\"Meat-Loving\", \"Meat Loving\", tweet)\n",
        "    tweet = re.sub(r\"facialabuse\", \"facial abuse\", tweet)\n",
        "    tweet = re.sub(r\"LakeCounty\", \"Lake County\", tweet)\n",
        "    tweet = re.sub(r\"BeingAuthor\", \"Being Author\", tweet)\n",
        "    tweet = re.sub(r\"withheavenly\", \"with heavenly\", tweet)\n",
        "    tweet = re.sub(r\"thankU\", \"thank you\", tweet)\n",
        "    tweet = re.sub(r\"iTunesMusic\", \"iTunes Music\", tweet)\n",
        "    tweet = re.sub(r\"OffensiveContent\", \"Offensive Content\", tweet)\n",
        "    tweet = re.sub(r\"WorstSummerJob\", \"Worst Summer Job\", tweet)\n",
        "    tweet = re.sub(r\"HarryBeCareful\", \"Harry Be Careful\", tweet)\n",
        "    tweet = re.sub(r\"NASASolarSystem\", \"NASA Solar System\", tweet)\n",
        "    tweet = re.sub(r\"animalrescue\", \"animal rescue\", tweet)\n",
        "    tweet = re.sub(r\"KurtSchlichter\", \"Kurt Schlichter\", tweet)\n",
        "    tweet = re.sub(r\"aRmageddon\", \"armageddon\", tweet)\n",
        "    tweet = re.sub(r\"Throwingknifes\", \"Throwing knives\", tweet)\n",
        "    tweet = re.sub(r\"GodsLove\", \"God's Love\", tweet)\n",
        "    tweet = re.sub(r\"bookboost\", \"book boost\", tweet)\n",
        "    tweet = re.sub(r\"ibooklove\", \"I book love\", tweet)\n",
        "    tweet = re.sub(r\"NestleIndia\", \"Nestle India\", tweet)\n",
        "    tweet = re.sub(r\"realDonaldTrump\", \"Donald Trump\", tweet)\n",
        "    tweet = re.sub(r\"DavidVonderhaar\", \"David Vonderhaar\", tweet)\n",
        "    tweet = re.sub(r\"CecilTheLion\", \"Cecil The Lion\", tweet)\n",
        "    tweet = re.sub(r\"weathernetwork\", \"weather network\", tweet)\n",
        "    tweet = re.sub(r\"withBioterrorism&use\", \"with Bioterrorism & use\", tweet)\n",
        "    tweet = re.sub(r\"Hostage&2\", \"Hostage & 2\", tweet)\n",
        "    tweet = re.sub(r\"GOPDebate\", \"GOP Debate\", tweet)\n",
        "    tweet = re.sub(r\"RickPerry\", \"Rick Perry\", tweet)\n",
        "    tweet = re.sub(r\"frontpage\", \"front page\", tweet)\n",
        "    tweet = re.sub(r\"NewsInTweets\", \"News In Tweets\", tweet)\n",
        "    tweet = re.sub(r\"ViralSpell\", \"Viral Spell\", tweet)\n",
        "    tweet = re.sub(r\"til_now\", \"until now\", tweet)\n",
        "    tweet = re.sub(r\"volcanoinRussia\", \"volcano in Russia\", tweet)\n",
        "    tweet = re.sub(r\"ZippedNews\", \"Zipped News\", tweet)\n",
        "    tweet = re.sub(r\"MicheleBachman\", \"Michele Bachman\", tweet)\n",
        "    tweet = re.sub(r\"53inch\", \"53 inch\", tweet)\n",
        "    tweet = re.sub(r\"KerrickTrial\", \"Kerrick Trial\", tweet)\n",
        "    tweet = re.sub(r\"abstorm\", \"Alberta Storm\", tweet)\n",
        "    tweet = re.sub(r\"Beyhive\", \"Beyonce hive\", tweet)\n",
        "    tweet = re.sub(r\"IDFire\", \"Idaho Fire\", tweet)\n",
        "    tweet = re.sub(r\"DETECTADO\", \"Detected\", tweet)\n",
        "    tweet = re.sub(r\"RockyFire\", \"Rocky Fire\", tweet)\n",
        "    tweet = re.sub(r\"Listen/Buy\", \"Listen / Buy\", tweet)\n",
        "    tweet = re.sub(r\"NickCannon\", \"Nick Cannon\", tweet)\n",
        "    tweet = re.sub(r\"FaroeIslands\", \"Faroe Islands\", tweet)\n",
        "    tweet = re.sub(r\"yycstorm\", \"Calgary Storm\", tweet)\n",
        "    tweet = re.sub(r\"IDPs:\", \"Internally Displaced People :\", tweet)\n",
        "    tweet = re.sub(r\"ArtistsUnited\", \"Artists United\", tweet)\n",
        "    tweet = re.sub(r\"ClaytonBryant\", \"Clayton Bryant\", tweet)\n",
        "    tweet = re.sub(r\"jimmyfallon\", \"jimmy fallon\", tweet)\n",
        "    \n",
        "    return tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V68ct8w-SZf",
        "colab_type": "text"
      },
      "source": [
        "# OTHER ABBREVIATIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo8zr2Hv90to",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#As we can see some same meaning words using different abbreviation, so that we try to make a function to align these words\n",
        "def abb1(text):\n",
        "    text = re.sub(r'^washington d c ', \"washington dc\", text)\n",
        "    text = re.sub(r'^washington +[\\w]*', \"washington dc\", text)\n",
        "    text = re.sub(r'^new york +[\\w]*', \"new york\", text)\n",
        "    text = re.sub(r'^nyc$', \"new york\", text)\n",
        "    text = re.sub(r'^chicago +[\\w]*', \"chicago\", text)\n",
        "    text = re.sub(r'^california +[\\w]*', \"california\", text)\n",
        "    text = re.sub(r'^los angeles +[\\w]*', \"los angeles\", text)\n",
        "    text = re.sub(r'^san francisco +[\\w]*', \"san francisco\", text)\n",
        "    text = re.sub(r'^london +[\\w]*', \"london\", text)\n",
        "    text = re.sub(r'^usa$', \"united states\", text)\n",
        "    text = re.sub(r'^us$', \"united states\", text)\n",
        "    text = re.sub(r'^uk$', \"united kingdom\", text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "def abb2(text):\n",
        "    abb = ['ak', 'al', 'az', 'ar', 'ca', 'co',\n",
        "           'ct', 'de', 'dc', 'fl', 'ga', 'hi',\n",
        "           'id', 'il', 'in', 'ia', 'ks', 'ky',\n",
        "           'la', 'me', 'mt', 'ne', 'nv', 'nh',\n",
        "           'nj', 'nm', 'ny', 'nc', 'nd', 'oh',\n",
        "           'ok', 'or', 'md', 'ma', 'mi', 'mn',\n",
        "           'ms', 'mo', 'pa', 'ri', 'sc', 'sd',\n",
        "           'tn', 'tx', 'ut', 'vt', 'va', 'wa',\n",
        "           'wv', 'wi', 'wy']\n",
        "    \n",
        "    for i in abb:\n",
        "        text = re.sub(r'^{0}$'.format(i), '', text)\n",
        "        \n",
        "    return text "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxQgsxF5du2H",
        "colab_type": "text"
      },
      "source": [
        "# PUNCTUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yw78-JD2XZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PUNCT_TO_REMOVE = string.punctuation\n",
        "def remove_punctuation(text):\n",
        "    \"\"\"custom function to remove the punctuation\"\"\"\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_4HNXIsdxq4",
        "colab_type": "text"
      },
      "source": [
        "# STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovx4WPv23FDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"custom function to remove the stopwords\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi-e2rVweao6",
        "colab_type": "text"
      },
      "source": [
        "# SPELLING CORRECTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqk4pWCHct1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_spellings(text):\n",
        "    spell = SpellChecker()\n",
        "    corrected_text = []\n",
        "    misspelled_words = spell.unknown(text.split())\n",
        "    for word in str(text).split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(spell.correction(word))\n",
        "        else:\n",
        "            corrected_text.append(word)\n",
        "           \n",
        "    \n",
        "    return \" \".join(corrected_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdD2YMr3A4sd",
        "colab_type": "text"
      },
      "source": [
        "# MAKING PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlM-40i0A-Uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "complete['text_cleaned'] = complete['text'].copy().apply(lambda x: replace_chat_word(x))\\\n",
        "                                                   .apply(lambda x: remove_url(x))\\\n",
        "                                                   .apply(lambda x: remove_emoji(x))\\\n",
        "                                                   .apply(lambda x: remove_emoticons(x))\\\n",
        "                                                   .apply(lambda x: remove_html(x))\\\n",
        "                                                   .apply(lambda x: gunes_evitan(x))\\\n",
        "                                                   .apply(lambda x: x.lower())\\\n",
        "                                                   .apply(lambda x: abb1(x))\\\n",
        "                                                   .apply(lambda x: abb2(x))\\\n",
        "                                                   .apply(lambda x: remove_punctuation(x))\\\n",
        "                                                   .apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz2qeGi5En5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "complete['text_cleaned'] = complete['text_cleaned'].apply(lambda x: correct_spellings(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjkGQH5g2TTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "complete['location'].fillna('no_location',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts1l8R9HIDxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "complete['location_cleaned'] = complete['location'].copy().apply(lambda x: str(x))\\\n",
        "                                                   .apply(lambda x: replace_chat_word(x))\\\n",
        "                                                   .apply(lambda x: remove_url(x))\\\n",
        "                                                   .apply(lambda x: remove_emoji(x))\\\n",
        "                                                   .apply(lambda x: remove_emoticons(x))\\\n",
        "                                                   .apply(lambda x: remove_html(x))\\\n",
        "                                                   .apply(lambda x: gunes_evitan(x))\\\n",
        "                                                   .apply(lambda x: x.lower())\\\n",
        "                                                   .apply(lambda x: abb1(x))\\\n",
        "                                                   .apply(lambda x: abb2(x))\\\n",
        "                                                   .apply(lambda x: remove_punctuation(x))\\\n",
        "                                                   .apply(lambda x: remove_stopwords(x))\\\n",
        "                                                   .apply(lambda x: correct_spellings(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmuDHA4kIYHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "complete['keyword_cleaned'] = complete['keyword'].copy().apply(lambda x: str(x))\\\n",
        "                                                   .apply(lambda x: replace_chat_word(x))\\\n",
        "                                                   .apply(lambda x: remove_url(x))\\\n",
        "                                                   .apply(lambda x: remove_emoji(x))\\\n",
        "                                                   .apply(lambda x: remove_emoticons(x))\\\n",
        "                                                   .apply(lambda x: remove_html(x))\\\n",
        "                                                   .apply(lambda x: gunes_evitan(x))\\\n",
        "                                                   .apply(lambda x: x.lower())\\\n",
        "                                                   .apply(lambda x: abb1(x))\\\n",
        "                                                   .apply(lambda x: abb2(x))\\\n",
        "                                                   .apply(lambda x: remove_punctuation(x))\\\n",
        "                                                   .apply(lambda x: remove_stopwords(x))\\\n",
        "                                                   .apply(lambda x: correct_spellings(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umVqeFtYRQrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "d81f6b8a-9699-470e-f562-141d1a9e1d01"
      },
      "source": [
        "from google.colab import files\n",
        "complete.to_csv('complete_cleaned.csv')\n",
        "files.download('complete_cleaned.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c1d8e0f1-e6f7-48f4-94a8-1863ebdc1766\", \"complete_cleaned.csv\", 2471999)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPWVgloIIhdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = complete[complete.istrain == 1]\n",
        "train.drop(columns='istrain', inplace=True)\n",
        "test = complete[complete.istrain == 0]\n",
        "test.drop(columns=['istrain','target'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCBZCOWZOV_b",
        "colab_type": "text"
      },
      "source": [
        "# Removing duplicates from the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WsNdDCxObkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicated = train.duplicated(subset=['location_cleaned','keyword_cleaned','text_cleaned'], keep = 'first').values\n",
        "\n",
        "not_duplicated = []\n",
        "for i in duplicated: \n",
        "  if i == True:\n",
        "    not_duplicated.append(False)\n",
        "  else:\n",
        "    not_duplicated.append(True)\n",
        "\n",
        "train = train[not_duplicated].reset_index(drop=True)\n",
        "x_train = train[['location_cleaned','keyword_cleaned','text_cleaned']]\n",
        "y_train = train[[not_duplicated]['target']\n",
        "x_test = test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjRgBZeoAwKH",
        "colab_type": "text"
      },
      "source": [
        "# SAVING DATASETS INTO CSV FILES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQxpqHDNYEeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.to_csv('x_train_clean.csv', index=False)\n",
        "x_test.to_csv('x_test_clean.csv', index=False)\n",
        "y_train.to_csv('y_train_clean.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CuZcOCtYu7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "outputId": "aef98a02-06db-4ef6-ec95-595f12bff1d4"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('x_train_clean.csv')\n",
        "files.download('x_test_clean.csv')\n",
        "files.download('y_train_clean.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_58fe577f-69a4-4077-a343-9fa508d24885\", \"train_clean.csv\", 1598669)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2a4c5579-a524-4f0b-8e35-0da774137a4b\", \"test_clean.csv\", 717723)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_da401087-2efc-4c75-b769-80ba0fd802b8\", \"y_train.csv\", 15233)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}