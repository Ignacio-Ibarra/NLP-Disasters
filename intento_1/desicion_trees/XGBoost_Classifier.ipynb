{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7bc5RI1T0KL"
   },
   "source": [
    "**This is a XGBoost only with numeric features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5_-VCPDKUUMo"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehZQObPqSscY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmYyaNtCt7mW"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('https://raw.githubusercontent.com/Ignacio-Ibarra/NLP-Disasters/intento_1_nacho/intento_1/train_no_duplicates_with_word_classes.csv',\\\n",
    "                         sep=',', usecols = ['url_count',\n",
    "       'hashtag_count', 'mention_count', 'digits_count', 'characters_count',\n",
    "       'characters_count_clean', 'characters_count_clean_sw', 'word_count',\n",
    "       'word_count_clean', 'word_count_clean_sw', 'avg_word_len',\n",
    "       'avg_word_len_clean_sw', 'PRP$', 'NNS', 'VBP', 'DT', 'NN', 'IN', 'MD',\n",
    "       'VB', 'JJ', 'PRP', 'JJS', 'VBD', 'TO', 'VBG', 'VBN', 'CC', 'CD', 'RB',\n",
    "       'EX', 'VBZ', 'WP', 'RP', 'JJR', 'WRB', '$', 'WDT', 'NNP', 'RBR', 'RBS',\n",
    "       'PDT', 'SYM', 'FW', 'UH', 'X', 'WP$', 'target'],\\\n",
    "       dtype = {'PRP$': 'int64', 'NNS': 'int64', 'VBP': 'int64', 'DT': 'int64', 'NN': 'int64', 'IN': 'int64', 'MD': 'int64',\n",
    "       'VB': 'int64', 'JJ': 'int64', 'PRP': 'int64', 'JJS': 'int64', 'VBD': 'int64', 'TO': 'int64', 'VBG': 'int64', 'VBN': 'int64',\\\n",
    "       'CC': 'int64', 'CD': 'int64', 'RB': 'int64','EX': 'int64', 'VBZ': 'int64', 'WP': 'int64', 'RP': 'int64', 'JJR': 'int64',\\\n",
    "       'WRB': 'int64', '$': 'int64', 'WDT': 'int64', 'NNP': 'int64', 'RBR': 'int64', 'RBS': 'int64','PDT': 'int64', 'SYM': 'int64',\\\n",
    "       'FW': 'int64', 'UH': 'int64', 'X': 'int64', 'WP$': 'int64', 'target': 'int64'})\n",
    "\n",
    "\n",
    "\n",
    "data_test = pd.read_csv('https://raw.githubusercontent.com/Ignacio-Ibarra/NLP-Disasters/intento_1_nacho/intento_1/featured_test.csv',sep=',')\n",
    "data_test = data_test[data_test.columns[1:]]\n",
    "data_test.columns = ['id', 'keyword', 'location', 'text', 'text_clean', 'text_clean_no_sw',\n",
    "       'url_count', 'hashtag_count', 'mention_count', 'digits_count',\n",
    "       'characters_count', 'characters_count_clean',\n",
    "       'characters_count_clean_sw', 'word_count', 'word_count_clean',\n",
    "       'word_count_clean_sw', 'avg_word_len', 'avg_word_len_clean_sw',\n",
    "       'tokenized_text', 'pos_tagged_text', 'pos_tagg_counts', 'RB', 'VBD',\n",
    "       'DT', 'JJ', 'NN', 'IN', 'VBZ', 'NNS', 'VBP', 'EX', 'VBG', 'VB', 'PRP',\n",
    "       'CD', 'CC', 'MD', 'RBR', 'WRB', 'WP', 'VBN', 'RP', 'PRP$', '$', 'TO',\n",
    "       'NNP', 'WDT', 'PDT', 'JJS', 'JJR', 'FW', 'RBS', 'X', 'UH']\n",
    "id = list(data_test.id)\n",
    "x_test_numeric = data_test[['url_count', 'hashtag_count', 'mention_count', 'digits_count',\n",
    "       'characters_count', 'characters_count_clean',\n",
    "       'characters_count_clean_sw', 'word_count', 'word_count_clean',\n",
    "       'word_count_clean_sw', 'avg_word_len', 'avg_word_len_clean_sw',\n",
    "       'RB', 'VBD','DT', 'JJ', 'NN', 'IN', 'VBZ', 'NNS', 'VBP', 'EX', 'VBG', 'VB', 'PRP',\n",
    "       'CD', 'CC', 'MD', 'RBR', 'WRB', 'WP', 'VBN', 'RP', 'PRP$', '$', 'TO',\n",
    "       'NNP', 'WDT', 'PDT', 'JJS', 'JJR', 'FW', 'RBS', 'X', 'UH']]\n",
    "\n",
    "drop = []\n",
    "for i in list(data_test.columns): \n",
    "  if i not in list(data_train.columns): \n",
    "    drop.append(i)\n",
    "\n",
    "data_test.drop(columns= drop, inplace=True)\n",
    "\n",
    "drop = []\n",
    "for i in list(data_train.columns): \n",
    "  if i not in list(data_test.columns) and i != 'target':\n",
    "    drop.append(i)\n",
    "\n",
    "data_train.drop(columns=drop, inplace=True)\n",
    "\n",
    "X_train, y_train = data_train.iloc[:,1:], data_train['target']\n",
    "X_test = data_test\n",
    "\n",
    "X_train.fillna(value=0, inplace = True)\n",
    "X_test.fillna(value=0, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47r7xOA2UJlB"
   },
   "source": [
    "# XGBoost Classifier test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sN1xfxDHUr7n"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5943d1bfe3f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OcFMdI__pZS9"
   },
   "source": [
    "## Hiper-params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BOWUTlUcpT8a"
   },
   "source": [
    "* **learning_rate:** tasa de aprendizaje\n",
    "* **max_depth:** máxima profundidad de cada árbol\n",
    "* **subsample:** porcentaje de muestras usadas para cada árbol (valor muy bajo, posible underfitting)\n",
    "* **colsample_bytree:** porcentaje de features usadas para cada árbol (valores muy alto, posible overfitting)\n",
    "* **n_estimators:** cantidad de árboles a construir.\n",
    "* **objective:** función de error a utilizar (algunas: reg:squarederror para regresión, reg:logistic o binary:logistic para clasificación)\n",
    "\n",
    "Parámetros de regularización:\n",
    "\n",
    "* **gamma:** umbral para hacer split basado en la reducción de error de hacer el nuevo split.\n",
    "* **alpha:** regularización para los pesos de las hojas. Un valor más alto genera una mayor regularización.\n",
    "* **lambda:** similar alpha pero para la sintonia fina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efa_Ng06VKjK"
   },
   "source": [
    "## K-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ZjEaMLTdvsR"
   },
   "source": [
    "Se usa el método **cv**\n",
    "\n",
    "Hiper-parámetros:\n",
    "\n",
    "* **nfolds:** K del k-fold\n",
    "* **num_boost_round:** cantidad de árboles a contruir (n_estimators)\n",
    "* **metrics:** la métrica de evaluación a utilizar\n",
    "* **as_pandas:** si los resultados lo devuelve en un DataFrame de pandas\n",
    "* **early_stopping_rounds:** terminar antes si la métrica no mejora luego de una cantidad de pasadas\n",
    "* **seed:** semilla para poder reproducir los resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCMIYhf4pEzC"
   },
   "source": [
    "### Data to DMatrix object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CWOoIK_pAri"
   },
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Pw3yjwtWvTT"
   },
   "source": [
    "## RondomizedSearch CV with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0spOR6mYUlZ"
   },
   "outputs": [],
   "source": [
    " from scipy import stats\n",
    " from scipy.stats import randint\n",
    " from sklearn.model_selection import RandomizedSearchCV\n",
    " from sklearn.metrics import accuracy_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "BhPJghQOYZEd",
    "outputId": "fff4e2b3-0407-450d-e5a6-630ccf085602"
   },
   "outputs": [],
   "source": [
    "clf_xgb = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "param_dist = {'n_estimators': stats.randint(70, 1000),\n",
    "              'learning_rate': stats.uniform(0.01, 0.6),\n",
    "              'subsample': stats.uniform(0.3, 0.9),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.9),\n",
    "             }\n",
    "\n",
    "clf_random = RandomizedSearchCV(clf_xgb, param_distributions = param_dist, n_iter = 100, scoring = 'roc_auc',\\\n",
    "                         verbose = 3, n_jobs = -1, return_train_score=True, cv=10)\n",
    "\n",
    "clf_random.fit(X_train,y_train)\n",
    "\n",
    "import winsound         # for sound  \n",
    "\n",
    "winsound.Beep(440, 250)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "XGBoost Classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
