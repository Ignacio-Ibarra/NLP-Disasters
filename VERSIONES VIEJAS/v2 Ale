{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP1 version Ale v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLTkLxPY/AgwT8bSuzWpkx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ignacio-Ibarra/NLP-Disasters/blob/master/TP1_version_Ale_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJlc0AI_QZYr",
        "colab_type": "text"
      },
      "source": [
        "# Librerias\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD5hp2AiNQDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('ggplot')\n",
        "from wordcloud import WordCloud\n",
        "import PIL\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop=set(stopwords.words('english'))\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "#para suprimir notacion cientifica en los outputs\n",
        "pd.options.display.float_format='{:20,.2f}'.format\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAUmA9iHTe--",
        "colab_type": "text"
      },
      "source": [
        "# Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI1kyzzgSAbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ui6ouJ_SVwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "link='https://drive.google.com/open?id=1Wuo42Fju9VOh2m5PV7q95TTUAIkrEwDD'\n",
        "fluff, id = link.split('=')\n",
        "print (id) # Verify that you have everything after '='"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FljNTbTSigo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkZHvF9eSUqL",
        "colab_type": "text"
      },
      "source": [
        "# Carga DF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHLtylTOSxYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading 'train.csv' into DataFrame\n",
        "train=pd.read_csv('train.csv')\n",
        "train.head(10) #Let's have a first view of the DataFrame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM8fF1mfLlQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('El DataFrame cuenta con {} filas y {} columnas'.format(train.shape[0],train.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZNmQNq2XafS",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning de tweets repetidos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uj3rciXX0Yp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicated=train.groupby(['text']).agg({'target':['count','nunique']}).reset_index()\n",
        "duplicated.sort_values(by=('target','count'),ascending=False).head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxaFvTNE5cb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-oU8LFHnXQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fUR24geTUgc",
        "colab_type": "text"
      },
      "source": [
        "Se observa que hay tweets que se repiten hasta 10 veces. A su vez, existen tweets a los que se les asignaron 2 targets al mismo tiempo (columna nunique). Esos datos se deben eliminar ya que afectan al set de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH3PF_CqYLJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contradiction=train.loc[:,['text','target']].groupby(['text']).transform('nunique')\n",
        "train['count_targets']=contradiction\n",
        "train=train[train.count_targets==1]\n",
        "train.drop('count_targets',axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjhM7POiQXRo",
        "colab_type": "text"
      },
      "source": [
        "Una vez eliminados los tweets contradictorios, se eliminan los tweets duplicados (salvo la primera ocurrencia)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG-uiorsSw4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop_duplicates(subset ='text', keep = 'first', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPHIwA-YR_4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('El DataFrame post cleaning cuenta con {} filas y {} columnas'.format(train.shape[0],train.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPfL1H9INgqJ",
        "colab_type": "text"
      },
      "source": [
        "# Proporción de Target Real/Not Real"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRYvc-RRNqAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cantidad de muestras \n",
        "sns.set_context('paper')\n",
        "\n",
        "x=train['target'].value_counts()\n",
        "g=sns.barplot(x.index,x)\n",
        "g.set_title('Barplot: Cantidad de tweets por Target\\n',fontsize=14)\n",
        "g.set_ylabel('Muestras')\n",
        "plt.xticks([0, 1], ['Not Real', 'Real'])\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q50NXU9OF9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels='Not Real','Real'\n",
        "g2=plt.pie(x,labels=labels,autopct='%1.1f%%',startangle=140)\n",
        "plt.axis('equal')\n",
        "plt.title('Pie chart: Training Tweets: Real or not?')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZou9mMjOQ_S",
        "colab_type": "text"
      },
      "source": [
        "Se observa mayor proporción de tweets de clase \"Not Real\" sobre los de clase \"Real\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBQCRHaV2WK0",
        "colab_type": "text"
      },
      "source": [
        "Se puede dividir el DF en 2 subsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgsgsgTr2bbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train1=train[train['target']==1]\n",
        "train0=train[train['target']==0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxKae_zvPHxh",
        "colab_type": "text"
      },
      "source": [
        "# Análisis de Keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Annu4qvFPOD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def percent_real_disaster(x):\n",
        "    return x.mean()*100 \n",
        "\n",
        "\n",
        "grouped=train.groupby(['keyword']).agg({'target':[percent_real_disaster]}).sort_values(by=('target','percent_real_disaster'),ascending=False)\n",
        "grouped=grouped.reset_index()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMzU3eXhVUqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['hashtag_count'].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDwMGdaDPffb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot \n",
        "sns.set_context('paper')\n",
        "#Ploteo el total de tweets por keyword\n",
        "f, axes = plt.subplots(1,2, figsize=(17, 10), sharex=True)\n",
        "\n",
        "#Los keywords con mayor proporción de tweets Reales\n",
        "sns.set_color_codes(\"pastel\")\n",
        "g1=sns.barplot(ax=axes[0],x=100,y='keyword',data=grouped.head(25),label='Not Real', color=\"b\")\n",
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(ax=axes[0],x=('target','percent_real_disaster'),y='keyword',data=grouped.head(25), label='Real',color=\"b\")\n",
        "g1.set_ylabel('keywords')\n",
        "g1.set_xlabel('Porcentaje')\n",
        "g1.set_title('Top 25 Real Disasters by Keyword')\n",
        "\n",
        "#los peores 10\n",
        "sns.set_color_codes(\"pastel\")\n",
        "g2=sns.barplot(ax=axes[1],x=100,y='keyword',data=grouped.tail(25), label='Not Real',color=\"r\")\n",
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(ax=axes[1],x=('target','percent_real_disaster'),y='keyword',data=grouped.tail(25),label='Real', color=\"r\")\n",
        "g2.set_ylabel('')\n",
        "g2.set_xlabel('Porcentaje')\n",
        "g2.set_title('Top 25 NOT Real Disasters by Keyword')\n",
        "\n",
        "# Legend\n",
        "g1.legend(ncol=1, loc=\"lower right\", frameon=True)\n",
        "g2.legend(ncol=1, loc=\"lower right\", frameon=True)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6A_MSsYXdCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['keyword'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZTHL46kRJlz",
        "colab_type": "text"
      },
      "source": [
        "En la figura se la izquiera se ilustran 25 keywords con porcentajes de Target \"Real\" mayores al 75%. Se observan keywords referentes a desastres naturales (*drought, forest fire, violent storm)* o edilicios (*bridge collapse, buildings on fire*). También se encuentran tragedias mortales (*mass murder, airplane accident, nuclear disaster, suicide bombing*). Otros keywords incluyen lenguaje de noticias (*casualties, evacuated, rescuers*). \n",
        "\n",
        "Por otro lado, en la figura de la derecha, se observan los 25 keywords con menores porcentajes de veracidad. En su mayoría se trata de palabras que servirían para describir tragedias pero que a su vez pueden usarse en muchos otros contextos. Un ejemplo de esto es el keyword \"body bag\", con un porcentaje de targets Reales menor al 5%. El término por si solo sonaría alarmante, pero veamos las acepciones de la palabra:\n",
        "\n",
        "1.   Bolsa para guardar cadáveres\n",
        "2.   Una clase de cartera/mochila\n",
        "3.   Según *Urban Dictionary*, \"To boddybag an oponent\" es asegurar la victoria sobre el oponente (algo así como \"kick ass\"), slang muy utilizado en las batallas de rap.\n",
        "4.   Otra acepción de *Urban Dictionary*, \"Bodybagging\" es robarle un chiste a otro comediante y hacerlo pasar como propio. \n",
        "\n",
        "Se observa también mayor cantidad de verbos y adjetivos que en el otro target.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bBX5Vz7dYlE",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning: elimino signos de puntuación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GonroTVYfG4M",
        "colab_type": "text"
      },
      "source": [
        "Se eliminan los signos de puntuación salvo @, # y (:,/,.) ya que representan elementos característicos de tweets : menciones, hashtags y links. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sph7dxnBdgRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def deletePunctuation(inputString):\n",
        "  aux=string.punctuation\n",
        "  puncts=aux.translate(str.maketrans(\"#@:/.\",\"     \"))\n",
        "  auxstring=\" \" * len(puncts)\n",
        "  outputString=inputString.translate(str.maketrans(puncts,auxstring))\n",
        "  return outputString\n",
        "\n",
        "train['text'] = train['text'].apply(lambda x: deletePunctuation(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEdGGvBGamx1",
        "colab_type": "text"
      },
      "source": [
        "# Análisis de Pronombres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK6OA798aqrE",
        "colab_type": "text"
      },
      "source": [
        "Se propone un análisis de cantidad de apariciones de pronombres en tweets según su target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi7A0UUEVczt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_tokens(target):\n",
        "    text_tokens=[]\n",
        "    for x in train[train['target']==target]['text'].str.split():\n",
        "        for i in x:\n",
        "            text_tokens.append(i)\n",
        "    return text_tokens\n",
        "\n",
        "#Analizo tweets con target Not Real\n",
        "corpus=generate_tokens(0)\n",
        "\n",
        "dic=defaultdict(int)\n",
        "pronouns={'I','me','my','mine','myself','you','your','yours','yourself',\\\n",
        "          'he','him','his','himself','she','her','hers','herself',\\\n",
        "          'it','its','itself','we','us','our','ours','ourselves',\\\n",
        "          'they','them','their','theirs','themselves','yourselves'}\n",
        "\n",
        "for word in corpus:\n",
        "    if word in pronouns:\n",
        "        dic[word]+=1\n",
        "        \n",
        "top0=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:11]\n",
        "x0,y=zip(*top0)\n",
        "y0=tuple(i/(len(train0['text'])) for i in y)\n",
        "\n",
        "#Analizo tweets con target Real\n",
        "\n",
        "text_tokens=generate_tokens(1)\n",
        "dic=defaultdict(int)\n",
        "\n",
        "for word in text_tokens:\n",
        "    if word in pronouns:\n",
        "        dic[word]+=1\n",
        "\n",
        "top1=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:11]\n",
        "x1,y=zip(*top1)\n",
        "y1=tuple(i/(len(train1['text'])) for i in y)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT8DTRNM2mx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pronouns0=pd.DataFrame(top0,columns=['pronoun','cantidad_not_real'])\n",
        "pronouns1=pd.DataFrame(top1,columns=['pronoun','cantidad_real'])\n",
        "\n",
        "pronouns=pronouns0.merge(pronouns1, how='inner')\n",
        "pronouns['cantidad_not_real']=100*pronouns['cantidad_not_real']/len(train0)\n",
        "pronouns['cantidad_real']=100*pronouns['cantidad_real']/len(train1)\n",
        "\n",
        "# Setting the positions and width for the bars\n",
        "pos = list(range(len(pronouns['pronoun']))) \n",
        "width = 0.25 \n",
        "\n",
        "# Plotting the bars\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "\n",
        "# Create a bar with cantidad_not_real data,\n",
        "# in position pos,\n",
        "plt.bar(pos, \n",
        "        #using df['pre_score'] data,\n",
        "        pronouns['cantidad_not_real'], \n",
        "        # of width\n",
        "        width, \n",
        "        # with alpha 0.5\n",
        "        alpha=0.5, \n",
        "        # with label the first value in first_name\n",
        "        label=pronouns['pronoun'][0]) \n",
        "\n",
        "# Create a bar with mid_score data,\n",
        "# in position pos + some width buffer,\n",
        "plt.bar([p + width for p in pos], \n",
        "        #using df['mid_score'] data,\n",
        "        pronouns['cantidad_real'],\n",
        "        # of width\n",
        "        width, \n",
        "        # with alpha 0.5\n",
        "        alpha=0.5,  \n",
        "        # with label the second value in first_name\n",
        "        label=pronouns['pronoun'][1]) \n",
        "\n",
        "# Set the y axis label\n",
        "ax.set_ylabel('Porcentaje de apariciones por target')\n",
        "\n",
        "# Set the chart's title\n",
        "ax.set_title('Top 10 de pronombres en tweets')\n",
        "\n",
        "\n",
        "# Set the position of the x ticks\n",
        "ax.set_xticks([p + 0.5 * width for p in pos])\n",
        "\n",
        "# Set the labels for the x ticks\n",
        "ax.set_xticklabels(pronouns['pronoun'])\n",
        "\n",
        "\n",
        "# Adding the legend and showing the plot\n",
        "plt.legend(['Not Real', 'Real'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mltKoDDg2wZt",
        "colab_type": "text"
      },
      "source": [
        "En la figura se observan los pronombres con más apariciones para ambos targets. Se observa que los mismos 10 pronombres aparecen en ambos rankings. Sin embargo, todos los porcentajes de aparición de target Not Real superan a los de target Real. En partircular, los valores de \"I\", \"you\" y \"my\" para los targets Not Real triplican en porcentaje a los de target Real. \n",
        "La naturaleza de un tweet que expresa un desastre responde a un estilo de redacción con poca cantidad de pronombres respecto a un tweet \"normal\". Esto puede deberse a que no suele usarse la primera ni segunda persona del singular, y puede haber mayor cantidad de nombres propios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMyjy7lL8jdY",
        "colab_type": "text"
      },
      "source": [
        "# Análisis de características de tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCURBzI68oz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hasNumbers(inputString):\n",
        "  return any(w.isdigit() for w in str(inputString).split())\n",
        "\n",
        "train['characters_count'] = train['text'].apply(lambda x: len(str(x)))\n",
        "train['word_count'] = train['text'].apply(lambda x: len(str(x).split()))\n",
        "train['url_count'] = train['text'].apply(lambda x: any([w for w in str(x).lower().split() if 'http' in w]))\n",
        "train['hashtag_count'] = train['text'].apply(lambda x: any([c for c in str(x) if c == '#']))\n",
        "train['mention_count'] = train['text'].apply(lambda x: any([c for c in str(x) if c == '@']))\n",
        "train['digits'] = train['text'].apply(lambda x: hasNumbers(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7PD-7hieSDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train[(train['target']==1) & (train['hashtag_count']==2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tn5oQmg9qgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yet-8Qp2GYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanText(inputString):\n",
        "  text = re.sub(r'http\\S+', '', inputString)  \n",
        "  text2 = re.sub(r'@\\S+', '', text)  \n",
        "  return (text2)\n",
        " \n",
        "train['clean_text'] = train['text'].apply(lambda x: cleanText(x))\n",
        "\n",
        "train.loc[7612,'clean_text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cprxrX_85elW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "duplicated=train.groupby(['clean_text']).agg({'target':['count','nunique']}).reset_index()\n",
        "duplicated=duplicated.sort_values(by=('target','count'),ascending=False).head(230)\n",
        "duplicated"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
